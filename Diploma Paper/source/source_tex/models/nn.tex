\subsubsection{Neural Networks} \label{link::neural_networks}
Наиболее современным методом моделирования временных рядов как ранее описанных в настоящей работе, так и далее используемых в исследовании, является применение нейросетевого подхода, в основе которого лежит <<самообучающаяся>> функция, называемая нейронной сетью. 

Впервые предложенный Warren S. McCulloch и Walter Pitts \cite{mcculloch1943logical}, подход проведения вычислений сродни поведению нейрона стал набирать популярность как в областях применения: регрессия, классификация, кластеризация, так и в областях построения нейронных сетей. В 1961 году за счет трудов Frank Rosenblatt'а были изобретены многослойные персептроны \cite{rosenblatt1961principles}, за этим в 1980-х последовала разработка сверточных нейронных сетей, максимально эффективно --- на тот момент --- работающих с изображениями \cite{lecun1989backpropagation, lecun2015deep, lecun1989generalization}. После чего, когда речь зашла об обработке естественного языка были предложены рекуррентные нейронные сети, основанные не итеративном <<сборе информации>> о предоставляемых текстах \cite{hochreiter1997long, rumelhart1986learning}. 

В настоящий момент нейронные сети спокойно работают с видео, звуком, а также --- при определенных затратах вычислительных мощностей --- генерируют картинки. Однако State Of The Art (SOTA) почти во всех современных моделях глубокого обучения выступают трансформеры, в основе которых лежит механизм самовнимания \cite{attention_transformers}, позволяющий этим тяжелым сетям обрабатывать огромное количество информации, а что самое главное --- запоминать и вычленять. Однако в области прогнозирования временных рядом трансформеры пока что не занимают лидирующих позиций \cite{transformers_are_useless_for_TSF}.  Поэтому, так как в ценах/доходностях акций, конечно, содержится информация, однако она не носит лингвистический характер, которая позволяла бы применять подход контекстного анализа --- предсказываем то или иное слово в тесте, исходя из его контекста \cite{word2vec_2013}. Именно по этой причине в настоящем исследовании не рассматривается применение данный алгоритмов глубокого обучения при построении прогноза временного ряда.

\input{./source/source_tex/models/nn/mlp}
\input{./source/source_tex/models/nn/rnn}
\input{./source/source_tex/models/nn/wn}
\input{./source/source_tex/models/nn/optim}