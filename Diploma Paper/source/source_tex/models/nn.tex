\subsubsection{Neural Networks} \label{link::neural_networks}
Наиболее современным методом моделирования временных рядов как ранее описанных в настоящей работе, так и далее используемых в исследовании, является применение нейросетевого подхода, в основе которого лежит <<самообучающаяся>> функция, называемая нейронной сетью. 

Впервые предложенный Warren S. McCulloch и Walter Pitts \cite{mcculloch1943logical}, подход проведения вычислений сродни поведению нейрона стал набирать популярность как в областях применения: регрессия, классификация, кластеризация --- так и в областях построения нейронных сетей. В 1961 году за счет трудов Frank Rosenblatt'а были изобретены многослойные персептроны \cite{rosenblatt1961principles}, за этим в 1980-х последовала разработка сверточных нейронных сетей, максимально эффективно --- на тот момент --- работающих с изображениями \cite{lecun1989backpropagation, lecun2015deep, lecun1989generalization}. После чего, когда речь зашла об обработке естественного языка были предложены рекуррентные нейронные сети, основанные на итеративном <<сборе информации>> о предоставляемых текстах \cite{hochreiter1997long, rumelhart1986learning}. 

В настоящий момент нейронные сети спокойно работают с видео, звуком, а также --- при определенных затратах вычислительных мощностей --- генерируют картинки. Однако State Of The Art (SOTA) почти во всех современных моделях глубокого обучения выступают трансформеры, в основе которых лежит механизм самовнимания \cite{attention_transformers}, позволяющий этим тяжелым сетям обрабатывать огромное количество информации, а что самое главное --- запоминать и вычленять наиболее важную. Однако в области прогнозирования временных рядом трансформеры пока что не занимают лидирующих позиций \cite{transformers_are_useless_for_TSF}.  Поэтому, так как в ценах/доходностях акций, конечно, содержится информация, которая позволяла бы применять подход контекстного анализа --- предсказываем то или иное слово в тесте, исходя из его контекста \cite{word2vec_2013}, однако она не носит лингвистический характер, что значительно усложняет сам процесс моделирования временного ряда. Именно по этой причине в настоящем исследовании не рассматривается применение трансформеров при построении прогноза временного ряда.

В настоящее время SOTA для работы с временными рядами является модель N~---~BEATS \cite{oreshkin2019n}, использующая в своей основе принцип нейронного бустинга \cite{schapire2003boosting}. Усовершенствованием данной модели является иной подход N~---~HiTS \cite{challu2022n}, основанный на вычленении долгосрочных паттернов из сигналов посредством реализации слоя MaxPooling с варьируемым размером ядра.

Замечаем, что в настоящем исследовании данные модели не рассматриваются, так как основная задача --- доказательство того, что нейросетевой подход дает более точный результат, чем эконометрический. Следовательно, выбор наиболее качественных и <<хороших>> моделей из области статистики и эконометрики предоставляет примерную точную верхнюю грань множества данных моделей, а выбор наиболее слабых нейронных сетей --- примерную точную нижнюю грань множества нейронных сетей. Таким образом, подчеркиваем нецелесообразность включения в исследование моделей N~---~BEATS и N~---~HiTS, так как они с большей вероятностью дают результат лучше. В противном случае, появляется качественное <<смещение>> результата.

\input{./source/source_tex/models/nn/mlp}
\input{./source/source_tex/models/nn/rnn}
\input{./source/source_tex/models/nn/wn}